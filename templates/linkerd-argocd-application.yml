apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ${name}
  # You'll usually want to add your resources to the argocd namespace.
  namespace: ${argocd_namespace}
  %{if cascade_delete == true}
  # Add a this finalizer ONLY if you want these to cascade delete.
  finalizers:
    - resources-finalizer.argocd.argoproj.io
  %{ endif }
spec:
  # The project the application belongs to.
  project: ${project}

  # Source of the application manifests
  source:
    repoURL: ${helm_repo_url}
    targetRevision: ${target_revision}
    path: ${path}

    # helm specific config
    helm:
      # Extra parameters to set (same as setting through values.yaml, but these take precedence)
      parameters:
      - name: "nginx-ingress.controller.service.annotations.external-dns\\.alpha\\.kubernetes\\.io/hostname"
        value: mydomain.example.com
      - name: "ingress.annotations.kubernetes\\.io/tls-acme"
        value: "true"
        forceString: true # ensures that value is treated as a string

      # Release name override (defaults to application name)
      releaseName: ${release_name}

      # Values file as block file
      values: |
        ingress:
          enabled: true
          path: /
          hosts:
            - mydomain.example.com
          annotations:
            kubernetes.io/ingress.class: nginx
            kubernetes.io/tls-acme: "true"
          labels: {}
          tls:
            - secretName: mydomain-tls
              hosts:
                - mydomain.example.com

      %{if helm_template_version != null}
      # Optional Helm version to template with. If omitted it will fallback to look at the 'apiVersion' in Chart.yaml
      # and decide which Helm binary to use automatically. This field can be either 'v2' or 'v3'.
      version: ${helm_template_version}
      %{ endif }

  # Destination cluster and namespace to deploy the application
  destination:
    server: ${destination_server}
    namespace: ${namespace}

  # Sync policy
  syncPolicy:
    automated: # automated sync by default retries failed attempts 5 times with following delays between attempts ( 5s, 10s, 20s, 40s, 80s ); retry controlled using `retry` field.
      prune: ${automated_prune} # Specifies if resources should be pruned during auto-syncing ( false by default ).
      selfHeal: ${automated_self_heal} # Specifies if partial app sync should be executed when resources are changed only in target Kubernetes cluster and no git change detected ( false by default ).
    syncOptions:     # Sync options which modifies sync behavior
    - Validate=${sync_options_validate} # disables resource validation (equivalent to 'kubectl apply --validate=true')
    - CreateNamespace=${sync_options_create_namespace} # Namespace Auto-Creation ensures that namespace specified as the application destination exists in the destination cluster.
    # The retry feature is available since v1.7
    retry:
      limit: ${retry_limit} # number of failed sync attempt retries; unlimited number of attempts if less than 0
      backoff:
        duration: ${retry_backoff_duration} # the amount to back off. Default unit is seconds, but could also be a duration (e.g. "2m", "1h")
        factor: ${retry_backoff_factor} # a factor to multiply the base duration after each failed retry
        maxDuration: ${retry_backoff_max_duration} # the maximum amount of time allowed for the backoff strategy

  # Ignore differences at the specified json pointers
  ignoreDifferences:
  %{ for difference in ignore_differences ~}
  - group: ${difference.group}
    kind: ${difference.kind}
    jsonPointers:
    %{ for different_pointer in difference.jsonPointers ~}
    - ${different_pointer}
    %{ endfor ~}
  %{ endfor ~}
